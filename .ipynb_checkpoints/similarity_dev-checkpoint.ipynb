{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3f4a4f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "import gzip\n",
    "import shutil\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c9da1465-0d11-49fd-93db-2d4f5c76811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_icao_codes = [\n",
    "    # Star Alliance\n",
    "    'AEE', 'ACA', 'CCA', 'AIC', 'ANZ', 'ANA', 'AAR', 'AUA', 'AVA', 'BEL', 'CMP', 'CTN', \n",
    "    'MSR', 'ETH', 'EVA', 'LOT', 'DLH', 'CSZ', 'SIA', 'SAA', 'SWR', 'TAP', 'THA', 'THY',\n",
    "\n",
    "    # Oneworld\n",
    "    'BAW', 'CPA', 'FJI', 'FIN', 'IBE', 'JAL', 'MAS', 'QFA', 'QTR', 'RAM', 'RJA', 'ALK',\n",
    "\n",
    "    # SkyTeam\n",
    "    'ARG', 'AMX', 'AEA', 'AFR', 'CAL', 'CES', 'GIA', 'KQA', 'KLM', 'KAL', 'MEA', 'SVA',\n",
    "    'SAS', 'ROT', 'HVN', 'VIR', 'CXA', 'AFL', \n",
    "\n",
    "    # Other flag carriers\n",
    "    'BBC', 'TAM', 'EIN', 'ELY', 'BWA', 'PIA', 'ETD', 'UAE', 'TUA', 'UZB', 'VCV', 'PAL', \n",
    "    'MGL', 'KZR', 'GFA', 'AUI', 'TAR', 'DAH',\n",
    "\n",
    "    # Low cost carriers\n",
    "    'RYR', 'IGO', 'EZY', 'AXM', 'GLO', 'NOZ', 'VLG', 'WZZ', 'JST'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0201216c-7dea-4708-aa5e-3854b3342e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing hour 00...\n",
      "processing hour 01...\n",
      "processing hour 02...\n",
      "processing hour 03...\n",
      "processing hour 04...\n",
      "processing hour 05...\n",
      "processing hour 06...\n",
      "processing hour 07...\n",
      "processing hour 08...\n",
      "processing hour 09...\n",
      "processing hour 10...\n",
      "processing hour 11...\n",
      "processing hour 12...\n",
      "processing hour 13...\n",
      "processing hour 14...\n",
      "processing hour 15...\n",
      "processing hour 16...\n",
      "processing hour 17...\n",
      "processing hour 18...\n",
      "processing hour 19...\n",
      "processing hour 20...\n",
      "processing hour 21...\n",
      "processing hour 22...\n",
      "processing hour 23...\n",
      "All hourly files processed and combined.\n"
     ]
    }
   ],
   "source": [
    "#import pandas as pd\n",
    "#import numpy as np\n",
    "#import os\n",
    "#import tarfile\n",
    "#import urllib.request\n",
    "#import gzip\n",
    "#import shutil\n",
    "#import re\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def is_valid_callsign(callsign):\n",
    "  if not isinstance(callsign, str):\n",
    "    return False\n",
    "\n",
    "  callsign = callsign.strip().upper()\n",
    "\n",
    "  # must be at least 4 chrs (eg 'UAL1') and at most 8\n",
    "  if not (4 <= len(callsign) <= 8):\n",
    "    return False\n",
    "\n",
    "  prefix = callsign[:3]\n",
    "  suffix = callsign[3:]\n",
    "\n",
    "  # prefix must be all letters (UAL, SIA, BAW)\n",
    "  if not prefix.isalpha():\n",
    "    return False\n",
    "\n",
    "  # suffix: 1–4 digits, possibly ending in 1 letter\n",
    "  if not re.fullmatch(r'\\d{1,4}[A-Z]?', suffix):\n",
    "    return False\n",
    "\n",
    "  return True\n",
    "\n",
    "BASE_URL = \"https://s3.opensky-network.org/data-samples/states/.2019-07-15\"\n",
    "HOURS = [f\"{h:02d}\" for h in range(24)]\n",
    "MASTER_DF = []\n",
    "\n",
    "for h in tqdm(HOURS): \n",
    "    # define download URL\n",
    "    #print(f\"processing hour {h}...\")\n",
    "    filename = f\"states_2019-07-15-{h}.csv.tar\"\n",
    "    url = f\"{BASE_URL}/{h}/{filename}\"\n",
    "    local_tar = f\"./temp/{filename}\"\n",
    "    \n",
    "    # download tarball from OpenSky\n",
    "    os.makedirs(\"./temp\", exist_ok=True)\n",
    "    urllib.request.urlretrieve(url, local_tar)\n",
    "\n",
    "    # extract .csv.gz\n",
    "    with tarfile.open(local_tar, \"r\") as tar:\n",
    "        tar.extractall(\"./temp\")\n",
    "        \n",
    "    for name in os.listdir(\"./temp\"):\n",
    "        if name.endswith(\".csv.gz\") and name.startswith(\"states_2019-07-15\"):\n",
    "            gz_path = f\"./temp/{name}\"\n",
    "            csv_path = gz_path[:-3]\n",
    "    \n",
    "            # decompress .gz\n",
    "            with gzip.open(gz_path, 'rb') as f_in:\n",
    "                with open(csv_path, 'wb') as f_out:\n",
    "                    shutil.copyfileobj(f_in, f_out)\n",
    "    \n",
    "            # load to pandas and filter\n",
    "            df = pd.read_csv(csv_path)\n",
    "            df.dropna(subset=[\"time\", \"callsign\", \"lat\", \"lon\", \"velocity\", \"heading\", \"baroaltitude\"], inplace=True)\n",
    "            MASTER_DF.append(df)\n",
    "            os.remove(gz_path)\n",
    "            os.remove(csv_path)\n",
    "\n",
    "    os.remove(local_tar)\n",
    "\n",
    "master_df = pd.concat(MASTER_DF, ignore_index=True)\n",
    "\n",
    "master_df[\"callsign\"] = master_df[\"callsign\"].str.strip()\n",
    "    \n",
    "# scale altitude and velocity globally\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(master_df[[\"velocity\", \"baroaltitude\"]].values)\n",
    "velocity = master_df[\"velocity\"].values.reshape(-1, 1)\n",
    "altitude = master_df[\"baroaltitude\"].values.reshape(-1, 1)\n",
    "scaled = scaler.transform(np.hstack([velocity, altitude]))\n",
    "velocity_z = scaled[:, 0]\n",
    "altitude_z = scaled[:, 1]\n",
    "master_df[\"velocity\"] = velocity_z\n",
    "master_df[\"altitude\"] = altitude_z\n",
    "    \n",
    "# transform heading to sin/cos \n",
    "heading_rad = np.deg2rad(master_df[\"heading\"].values)\n",
    "sin_heading = np.sin(heading_rad)\n",
    "cos_heading = np.cos(heading_rad)\n",
    "master_df[\"sin_heading\"] = sin_heading\n",
    "master_df[\"cos_heading\"] = cos_heading\n",
    "    \n",
    "cleaned_data = master_df[[\"time\", \"callsign\", \"lat\", \"lon\", \"velocity\", \"sin_heading\", \"cos_heading\", \"altitude\"]]\n",
    "\n",
    "valid_mask = cleaned_data['callsign'].apply(is_valid_callsign)\n",
    "cleaned_data = cleaned_data[valid_mask].copy()\n",
    "\n",
    "# save locally as parquet (~50M rows, ~2GB)\n",
    "cleaned_data.to_parquet(\"opensky_2019-07-15_raw.parquet\")\n",
    "print(\"All hourly files processed and combined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b3988fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FLIGHT_DURATION = 8 * 3600  # 8 hours in seconds\n",
    "RESAMPLE_INTERVAL = 60  # seconds\n",
    "TARGET_LENGTH = 200 # target vector dimension for similarity\n",
    "\n",
    "def preprocess_flight(df_flight):\n",
    "    df_flight = df_flight.sort_values(\"time\")\n",
    "    duration = df_flight[\"time\"].iloc[-1] - df_flight[\"time\"].iloc[0]\n",
    "    \n",
    "    if duration > MAX_FLIGHT_DURATION:\n",
    "        return None\n",
    "    \n",
    "    start_time = df_flight[\"time\"].iloc[0]\n",
    "    df_flight[\"elapsed\"] = df_flight[\"time\"] - start_time\n",
    "    # resample to 200 steps\n",
    "    idxs = np.linspace(0, len(df_flight) - 1, TARGET_LENGTH).astype(int)\n",
    "    df_flight = df_flight.iloc[idxs]\n",
    "    \n",
    "    origin_lat = df_flight.iloc[0][\"lat\"]\n",
    "    origin_lon = df_flight.iloc[0][\"lon\"]\n",
    "    df = df_flight.copy()\n",
    "    df[\"delta_lat\"] = df[\"lat\"] - origin_lat\n",
    "    df[\"delta_lon\"] = df[\"lon\"] - origin_lon\n",
    "\n",
    "    return df[[\"delta_lat\", \"delta_lon\", \"velocity\", \"sin_heading\", \"cos_heading\", \"altitude\"]]\n",
    "\n",
    "def extract_flight(data, callsign):\n",
    "    return data[data[\"callsign\"] == callsign]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ecaf186a-af03-454c-a31e-ee6631ad4a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_data = pd.read_parquet(\"opensky_2019-07-15_raw.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7c12b97a-b537-4e2c-8f68-29a94a5a4a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfo_lax = ['UAL2757', 'DAL409', 'UAL1200', 'UAL257', 'DAL2861', 'UAL613', 'DAL664', 'UAL256', 'DAL2600', 'AAL1851']\n",
    "den_ord = ['UAL1938', 'UAL781', 'UAL301', 'AAL2771', 'UAL532', 'UAL682', 'AAL2780', 'UAL336', 'AAL2470', 'AAL773']\n",
    "dfw_atl = ['DAL2010', 'AAL2749', 'DAL1890', 'DAL1966', 'AAL1309', 'DAL2310', 'DAL2269', 'AAL333', 'DAL1513', 'AAL2403']\n",
    "dca_bos = ['AAL2150', 'AAL2148', 'AAL2160', 'AAL2169', 'AAL2139', 'AAL2170', 'AAL2119', 'AAL2149', 'AAL2120', 'AAL2134']\n",
    "ord_lga = ['UAL1823', 'UAL1606', 'AAL129', 'AAL398', 'AAL527', 'DAL379', 'DAL585', 'UAL509', 'DAL2775', 'UAL639'] \n",
    "lax_jfk = ['AAL10', 'DAL1908', 'DAL1436', 'AAL118', 'DAL1258', 'AAL2', 'DAL2164', 'AAL238', 'AAL4', 'DAL816']\n",
    "iah_ord = ['UAL2131', 'UAL1854', 'UAL2246', 'ENY3331', 'UAL1835', 'ENY3621', 'UAL1403', 'UAL1160', 'AAL869', 'UAL1899']\n",
    "sfo_sea = ['UAL800', 'DAL2787', 'UAL2161', 'DAL0856', 'UAL1074', 'UAL351', 'UAL618', 'DAL2490', 'DAL2429', 'DAL1470']\n",
    "atl_mco = ['DAL1418', 'DAL863', 'DAL804', 'DAL1883', 'DAL1905', 'DAL2428', 'DAL897', 'DAL768', 'DAL1118', 'DAL186']\n",
    "lax_atl = ['DAL1901', 'AAL1071', 'DAL2213', 'DAL2270', 'DAL954', 'DAL1592', 'DAL2714', 'DAL1954', 'DAL1140', 'DAL516']\n",
    "routes = [sfo_lax, den_ord, dfw_atl, dca_bos, ord_lga, lax_jfk, iah_ord, sfo_sea, atl_mco, lax_atl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "99f60936-4965-42ff-ba45-88e49dc8c420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_route(data, callsigns):\n",
    "    matrices = []\n",
    "    for call in callsigns:\n",
    "        df_flight = extract_flight(data, call)\n",
    "        traj = preprocess_flight(df_flight)\n",
    "        if traj is None:\n",
    "            continue\n",
    "        matrices.append(traj)\n",
    "\n",
    "    if len(matrices) == 0:\n",
    "        return None\n",
    "\n",
    "    # shape: (num_flights, 200, 6)\n",
    "    stacked = np.stack(matrices, axis=0)\n",
    "    aggregate = stacked.mean(axis=0) \n",
    "\n",
    "    return aggregate.T \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "916156c9-5198-4dc2-a9e5-99ffb781e12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectors for 10 trunk routes\n",
    "route_vectors = []\n",
    "for r in tqdm(routes, desc = 'Aggregating Routes'):\n",
    "    agg = aggregate_route(master_data, r)\n",
    "    if agg is not None:\n",
    "        route_vectors.append(agg)\n",
    "\n",
    "np.save('route_vectors', route_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "56b57252-f99d-41e6-af1f-62cebc190895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AAB416', 'AAB553', 'AAB576', ..., 'ZAM47', 'ZAM49', 'ZAM53'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(master_data['callsign'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3b705c9f-6c2b-42b6-b879-cc6a1cc78113",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                   | 317/68211 [09:55<35:25:54,  1.88s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[111], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m all_callsigns \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(master_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcallsign\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(all_callsigns))):\n\u001b[0;32m----> 5\u001b[0m     vec \u001b[38;5;241m=\u001b[39m preprocess_flight(\u001b[43mextract_flight\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaster_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_callsigns\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      6\u001b[0m     flight_vectors\u001b[38;5;241m.\u001b[39mappend(vec)\n\u001b[1;32m      8\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflight_vectors\u001b[39m\u001b[38;5;124m'\u001b[39m, flight_vectors)\n",
      "Cell \u001b[0;32mIn[67], line 27\u001b[0m, in \u001b[0;36mextract_flight\u001b[0;34m(data, callsign)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mextract_flight\u001b[39m(data, callsign):\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data[\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallsign\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcallsign\u001b[49m]\n",
      "File \u001b[0;32m~/ars_env/lib/python3.9/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ars_env/lib/python3.9/site-packages/pandas/core/arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ars_env/lib/python3.9/site-packages/pandas/core/series.py:6119\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6116\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   6117\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 6119\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/ars_env/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:344\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m lvalues\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 344\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    347\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/ars_env/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:129\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m    127\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mvec_compare(x\u001b[38;5;241m.\u001b[39mravel(), y\u001b[38;5;241m.\u001b[39mravel(), op)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mlibops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscalar_compare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# vectors for ~60k flights in dataset\n",
    "flight_vectors = []\n",
    "all_callsigns = np.unique(master_data['callsign'])\n",
    "for c in tqdm(range(len(all_callsigns))):\n",
    "    vec = preprocess_flight(extract_flight(master_data, all_callsigns[c]))\n",
    "    flight_vectors.append(vec)\n",
    "\n",
    "np.save('flight_vectors', flight_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b727ba-3c25-4b6c-8a64-9e158cc213b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "all_callsigns = np.unique(master_data['callsign'])\n",
    "\n",
    "for call in tqdm(all_callsigns):\n",
    "    flight_df = preprocess_flight(extract_flight(master_data, call))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ars_env)",
   "language": "python",
   "name": "ars_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
