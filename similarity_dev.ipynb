{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f4a4f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "import gzip\n",
    "import shutil\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9da1465-0d11-49fd-93db-2d4f5c76811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_icao_codes = [\n",
    "    # Star Alliance\n",
    "    'AEE', 'ACA', 'CCA', 'AIC', 'ANZ', 'ANA', 'AAR', 'AUA', 'AVA', 'BEL', 'CMP', 'CTN', \n",
    "    'MSR', 'ETH', 'EVA', 'LOT', 'DLH', 'CSZ', 'SIA', 'SAA', 'SWR', 'TAP', 'THA', 'THY',\n",
    "\n",
    "    # Oneworld\n",
    "    'BAW', 'CPA', 'FJI', 'FIN', 'IBE', 'JAL', 'MAS', 'QFA', 'QTR', 'RAM', 'RJA', 'ALK',\n",
    "\n",
    "    # SkyTeam\n",
    "    'ARG', 'AMX', 'AEA', 'AFR', 'CAL', 'CES', 'GIA', 'KQA', 'KLM', 'KAL', 'MEA', 'SVA',\n",
    "    'SAS', 'ROT', 'HVN', 'VIR', 'CXA', 'AFL', \n",
    "\n",
    "    # Other flag carriers\n",
    "    'BBC', 'TAM', 'EIN', 'ELY', 'BWA', 'PIA', 'ETD', 'UAE', 'TUA', 'UZB', 'VCV', 'PAL', \n",
    "    'MGL', 'KZR', 'GFA', 'AUI', 'TAR', 'DAH',\n",
    "\n",
    "    # Low cost carriers\n",
    "    'RYR', 'IGO', 'EZY', 'AXM', 'GLO', 'NOZ', 'VLG', 'WZZ', 'JST',\n",
    "\n",
    "    # U.S. carriers\n",
    "    'UAL', 'AAL', 'DAL', 'ENY'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0201216c-7dea-4708-aa5e-3854b3342e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#import numpy as np\n",
    "#import os\n",
    "#import tarfile\n",
    "#import urllib.request\n",
    "#import gzip\n",
    "#import shutil\n",
    "#import re\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def is_valid_callsign(callsign):\n",
    "    if not isinstance(callsign, str):\n",
    "        return False\n",
    "\n",
    "    callsign = callsign.strip().upper()\n",
    "\n",
    "    # must be at least 4 chrs (eg 'UAL1') and at most 8\n",
    "    if not (4 <= len(callsign) <= 8):\n",
    "        return False\n",
    "\n",
    "    prefix = callsign[:3]\n",
    "    suffix = callsign[3:]\n",
    "\n",
    "    # prefix must be a major intl airline\n",
    "    if prefix not in airline_icao_codes:\n",
    "        return False   \n",
    "\n",
    "    # suffix: 1–4 digits, possibly ending in 1 letter\n",
    "    if not re.fullmatch(r'\\d{1,4}[A-Z]?', suffix):\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "BASE_URL = \"https://s3.opensky-network.org/data-samples/states/.2019-07-15\"\n",
    "HOURS = [f\"{h:02d}\" for h in range(24)]\n",
    "MASTER_DF = []\n",
    "\n",
    "for h in tqdm(HOURS, desc = 'Processing OpenSky data'): \n",
    "    # define download URL\n",
    "    filename = f\"states_2019-07-15-{h}.csv.tar\"\n",
    "    url = f\"{BASE_URL}/{h}/{filename}\"\n",
    "    local_tar = f\"./temp/{filename}\"\n",
    "    \n",
    "    # download tarball from OpenSky\n",
    "    os.makedirs(\"./temp\", exist_ok=True)\n",
    "    urllib.request.urlretrieve(url, local_tar)\n",
    "\n",
    "    # extract .csv.gz\n",
    "    with tarfile.open(local_tar, \"r\") as tar:\n",
    "        tar.extractall(\"./temp\")\n",
    "        \n",
    "    for name in os.listdir(\"./temp\"):\n",
    "        if name.endswith(\".csv.gz\") and name.startswith(\"states_2019-07-15\"):\n",
    "            gz_path = f\"./temp/{name}\"\n",
    "            csv_path = gz_path[:-3]\n",
    "    \n",
    "            # decompress .gz\n",
    "            with gzip.open(gz_path, 'rb') as f_in:\n",
    "                with open(csv_path, 'wb') as f_out:\n",
    "                    shutil.copyfileobj(f_in, f_out)\n",
    "    \n",
    "            # load to pandas and filter\n",
    "            df = pd.read_csv(csv_path)\n",
    "            df.dropna(subset=[\"time\", \"callsign\", \"lat\", \"lon\", \"velocity\", \"heading\", \"baroaltitude\"], inplace=True)\n",
    "            MASTER_DF.append(df)\n",
    "            os.remove(gz_path)\n",
    "            os.remove(csv_path)\n",
    "\n",
    "    os.remove(local_tar)\n",
    "\n",
    "master_df = pd.concat(MASTER_DF, ignore_index=True)\n",
    "\n",
    "master_df[\"callsign\"] = master_df[\"callsign\"].str.strip()\n",
    "    \n",
    "# transform heading to sin/cos \n",
    "heading_rad = np.deg2rad(master_df[\"heading\"].values)\n",
    "sin_heading = np.sin(heading_rad)\n",
    "cos_heading = np.cos(heading_rad)\n",
    "master_df[\"sin_heading\"] = sin_heading\n",
    "master_df[\"cos_heading\"] = cos_heading\n",
    "    \n",
    "# remove invalid callsigns\n",
    "print(\"Filtering callsigns...\")\n",
    "valid_mask = master_df['callsign'].apply(is_valid_callsign)\n",
    "cleaned_data = master_df[valid_mask].copy()\n",
    "\n",
    "# scale altitude and velocity globally\n",
    "print(\"Scaling features...\")\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(cleaned_data[[\"velocity\", \"baroaltitude\"]].values)\n",
    "velocity = cleaned_data[\"velocity\"].values.reshape(-1, 1)\n",
    "altitude = cleaned_data[\"baroaltitude\"].values.reshape(-1, 1)\n",
    "scaled = scaler.transform(np.hstack([velocity, altitude]))\n",
    "velocity_z = scaled[:, 0]\n",
    "altitude_z = scaled[:, 1]\n",
    "cleaned_data.loc[:, \"velocity\"] = velocity_z\n",
    "cleaned_data.loc[:, \"altitude\"] = altitude_z\n",
    "\n",
    "cleaned_filtered_data = cleaned_data[[\"time\", \"callsign\", \"lat\", \"lon\", \"velocity\", \"sin_heading\", \"cos_heading\", \"altitude\"]]\n",
    "\n",
    "# save locally as parquet (~11M rows, ~450MB)\n",
    "cleaned_filtered_data.to_parquet(\"data/opensky_2019-07-15.parquet\")\n",
    "print(\"All hourly files processed and combined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9be7827c-76d2-4593-9bdb-79e4764c356e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17276605, 8)\n"
     ]
    }
   ],
   "source": [
    "master_data = pd.read_parquet(\"data/opensky_2019-07-15.parquet\")\n",
    "print(master_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3988fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FLIGHT_DURATION = 8 * 3600  # 8 hours in seconds\n",
    "RESAMPLE_INTERVAL = 60  # seconds\n",
    "TARGET_LENGTH = 200 # target vector dimension for similarity\n",
    "\n",
    "def preprocess_flight(df_flight):\n",
    "    df_flight = df_flight.sort_values(\"time\")\n",
    "    duration = df_flight[\"time\"].iloc[-1] - df_flight[\"time\"].iloc[0]\n",
    "    \n",
    "    if duration > MAX_FLIGHT_DURATION:\n",
    "        return None\n",
    "    \n",
    "    start_time = df_flight[\"time\"].iloc[0]\n",
    "    df_flight[\"elapsed\"] = df_flight[\"time\"] - start_time\n",
    "    # resample to 200 steps\n",
    "    idxs = np.linspace(0, len(df_flight) - 1, TARGET_LENGTH).astype(int)\n",
    "    df_flight = df_flight.iloc[idxs]\n",
    "    \n",
    "    origin_lat = df_flight.iloc[0][\"lat\"]\n",
    "    origin_lon = df_flight.iloc[0][\"lon\"]\n",
    "    df = df_flight.copy()\n",
    "    df[\"delta_lat\"] = df[\"lat\"] - origin_lat\n",
    "    df[\"delta_lon\"] = df[\"lon\"] - origin_lon\n",
    "\n",
    "    return df[[\"delta_lat\", \"delta_lon\", \"velocity\", \"sin_heading\", \"cos_heading\", \"altitude\"]]\n",
    "\n",
    "def extract_flight(data, callsign):\n",
    "    return data[data[\"callsign\"] == callsign]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c12b97a-b537-4e2c-8f68-29a94a5a4a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfo_lax = ['UAL2757', 'DAL409', 'UAL1200', 'UAL257', 'DAL2861', 'UAL613', 'DAL664', 'UAL256', 'DAL2600', 'AAL1851']\n",
    "den_ord = ['UAL1938', 'UAL781', 'UAL301', 'AAL2771', 'UAL532', 'UAL682', 'AAL2780', 'UAL336', 'AAL2470', 'AAL773']\n",
    "dfw_atl = ['DAL2010', 'AAL2749', 'DAL1890', 'DAL1966', 'AAL1309', 'DAL2310', 'DAL2269', 'AAL333', 'DAL1513', 'AAL2403']\n",
    "dca_bos = ['AAL2150', 'AAL2148', 'AAL2160', 'AAL2169', 'AAL2139', 'AAL2170', 'AAL2119', 'AAL2149', 'AAL2120', 'AAL2134']\n",
    "ord_lga = ['UAL1823', 'UAL1606', 'AAL129', 'AAL398', 'AAL527', 'DAL379', 'DAL585', 'UAL509', 'DAL2775', 'UAL639'] \n",
    "lax_jfk = ['AAL10', 'DAL1908', 'DAL1436', 'AAL118', 'DAL1258', 'AAL2', 'DAL2164', 'AAL238', 'AAL4', 'DAL816']\n",
    "iah_ord = ['UAL2131', 'UAL1854', 'UAL2246', 'ENY3331', 'UAL1835', 'ENY3621', 'UAL1403', 'UAL1160', 'AAL869', 'UAL1899']\n",
    "sfo_sea = ['UAL800', 'DAL2787', 'UAL2161', 'DAL0856', 'UAL1074', 'UAL351', 'UAL618', 'DAL2490', 'DAL2429', 'DAL1470']\n",
    "atl_mco = ['DAL1418', 'DAL863', 'DAL804', 'DAL1883', 'DAL1905', 'DAL2428', 'DAL897', 'DAL768', 'DAL1118', 'DAL186']\n",
    "lax_atl = ['DAL1901', 'AAL1071', 'DAL2213', 'DAL2270', 'DAL954', 'DAL1592', 'DAL2714', 'DAL1954', 'DAL1140', 'DAL516']\n",
    "routes = [sfo_lax, den_ord, dfw_atl, dca_bos, ord_lga, lax_jfk, iah_ord, sfo_sea, atl_mco, lax_atl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f60936-4965-42ff-ba45-88e49dc8c420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_route(data, callsigns):\n",
    "    matrices = []\n",
    "    for call in callsigns:\n",
    "        df_flight = extract_flight(data, call)\n",
    "        traj = preprocess_flight(df_flight)\n",
    "        if traj is None:\n",
    "            continue\n",
    "        matrices.append(traj)\n",
    "\n",
    "    if len(matrices) == 0:\n",
    "        return None\n",
    "\n",
    "    # shape: (num_flights, 200, 6)\n",
    "    stacked = np.stack(matrices, axis=0)\n",
    "    aggregate = stacked.mean(axis=0) \n",
    "\n",
    "    return aggregate\n",
    "\n",
    "# vectors for 10 trunk routes\n",
    "trunk_vectors = []\n",
    "for r in tqdm(routes, desc = 'Aggregating Trunk Routes'):\n",
    "    agg = aggregate_route(master_data, r)\n",
    "    if agg is not None:\n",
    "        trunk_vectors.append(agg)\n",
    "\n",
    "np.save('data/trunk_vectors', trunk_vectors)\n",
    "\n",
    "# remove flights by US carriers after aggregation\n",
    "def is_non_us_callsign(callsign):\n",
    "    prefix = callsign[:3]\n",
    "    if prefix in ['UAL', 'DAL', 'AAL', 'ENY']:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "us_mask = master_data['callsign'].apply(is_non_us_callsign)\n",
    "master_data = master_data[us_mask].copy()\n",
    "print(master_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b705c9f-6c2b-42b6-b879-cc6a1cc78113",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                    | 109/22618 [01:06<3:45:23,  1.66it/s]"
     ]
    }
   ],
   "source": [
    "# vectors for ~22k flights in dataset\n",
    "import pickle\n",
    "\n",
    "flight_vectors = {}\n",
    "all_callsigns = np.unique(master_data['callsign'])\n",
    "\n",
    "for c in tqdm(all_callsigns):\n",
    "    df = extract_flight(master_data, c)\n",
    "    vec = preprocess_flight(df)\n",
    "    if vec is not None:\n",
    "        flight_vectors[c] = vec\n",
    "\n",
    "# Save clean dictionary\n",
    "with open('data/flight_vectors.pkl', 'wb') as f:\n",
    "    pickle.dump(flight_vectors, f)\n",
    "\n",
    "print(f\"Saved {len(flight_vectors)} valid vectors to data/flight_vectors.pkl\")\n",
    "\n",
    "'''\n",
    "for c in tqdm(range(len(all_callsigns))):\n",
    "    vec = preprocess_flight(extract_flight(master_data, all_callsigns[c]))\n",
    "    flight_vectors[all_callsigns[c]] = vec\n",
    "\n",
    "np.savez('data/flight_vectors', flight_vectors)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dd53de-554a-4e29-a5c2-382e923c3c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trunk_vectors = np.load('data/trunk_vectors.npy')\n",
    "with open(\"flight_vectors.pkl\", \"rb\") as f:\n",
    "    flight_vectors = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b9d678-c44b-4ea8-9b3f-871149d439c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = np.load('data/flight_vectors.npz', allow_pickle = True)\n",
    "flight_vectors = raw['arr_0'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b727ba-3c25-4b6c-8a64-9e158cc213b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import euclidean\n",
    "import heapq\n",
    "from collections import defaultdict\n",
    "\n",
    "def compute_dtw(vec1, vec2):\n",
    "    score, _ = fastdtw(vec1, vec2, dist=euclidean)\n",
    "    return score\n",
    "\n",
    "def moved_enough(vec, min_displacement_km=100):\n",
    "    # roughly scaled for lat/lon in degrees (~111 km per deg)\n",
    "    start = vec.iloc[0, :2]\n",
    "    end = vec.iloc[-1, :2]\n",
    "    displacement_deg = np.linalg.norm(end - start)\n",
    "    displacement_km = displacement_deg * 111  # approximation\n",
    "    return displacement_km >= min_displacement_km\n",
    "\n",
    "def top_k_dtw(trunk_vectors, flight_vectors, k=5):\n",
    "    topk = defaultdict(list)\n",
    "\n",
    "    for callsign, vec in tqdm(flight_vectors.items(), desc=\"Flight vectors\"):\n",
    "        alt_start = vec.iloc[0,5]\n",
    "        alt_end = vec.iloc[-1,5]\n",
    "\n",
    "        # valid flights must have low starting/ending altitude and traveled at least 100 km\n",
    "        if alt_start >= 0 or alt_end >= 0 or not moved_enough(vec):\n",
    "            continue\n",
    "        \n",
    "        for i, trunk_vec in enumerate(trunk_vectors):\n",
    "            score = compute_dtw(vec, trunk_vec)\n",
    "            # use minheap with negative score to simulate maxheap\n",
    "            if len(topk[i]) < k:\n",
    "                heapq.heappush(topk[i], (-score, callsign))\n",
    "            else:\n",
    "                heapq.heappushpop(topk[i], (-score, callsign))\n",
    "\n",
    "    for i in topk:\n",
    "        topk[i].sort()\n",
    "\n",
    "    return topk\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262970e7-c8dc-40cc-bae7-ebfe40fc3e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_vectors = {k: v for k, v in flight_vectors.items() if v is not None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ac1667-1c6d-409b-b73c-2ae2f7667739",
   "metadata": {},
   "outputs": [],
   "source": [
    "topk = top_k_dtw(trunk_vectors, flight_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f397e96a-5f83-4701-953b-f5e72bc78787",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76056a2-db51-4545-b53b-69ae74d9540b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp(topk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4879f3-6d06-4198-905f-d3312f799f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def serialize_json(topk_dict, trunk_labels, out_path):\n",
    "    serializable = {\n",
    "        trunk_labels[i]: [\n",
    "            {\"callsign\": callsign, \"dtw_score\": -score}\n",
    "            for score, callsign in sorted(results)\n",
    "        ]\n",
    "        for i, results in topk_dict.items()\n",
    "    }\n",
    "\n",
    "    with open(out_path, \"w\") as f:\n",
    "        json.dump(serializable, f, indent = 2)\n",
    "\n",
    "    print(f\"saved top-k results to {out_path}\")\n",
    "\n",
    "trunk_labels = {\n",
    "  0: \"sfo_lax\",\n",
    "  1: \"den_ord\",\n",
    "  2: \"lax_jfk\",\n",
    "  3: \"atl_dfw\",\n",
    "  4: \"bos_dca\",\n",
    "  5: \"jfk_ord\",\n",
    "  6: \"iah_ord\",\n",
    "  7: \"sfo_sea\",\n",
    "  8: \"mco_atl\",\n",
    "  9: \"lax_atl\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183aac43-7cd8-469a-8888-663d5fa790cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "serialize_topk(topk, trunk_labels, out_path=\"data/results/topk_dtw.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ars_env)",
   "language": "python",
   "name": "ars_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
